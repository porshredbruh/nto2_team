# НТО 2025/2026 — Профиль «Искусственный интеллект»



## Командный этап



---



## 1. Описание задачи



**Контекст:** Книжная платформа различает два типа пользовательской активности: добавление книги в «планы» (`has_read=0`) и фактическое прочтение (`has_read=1`). Это сигналы разной силы: намерение прочесть не всегда приводит к реальному действию.

**Цель:** Разработать модель, которая сможет правильно упорядочить смешанный список книг-кандидатов по **трехуровневой иерархии релевантности**:
1. **Высшая ценность (2 балла):** Книги, которые пользователь действительно прочитал (`has_read=1`)
2. **Средняя ценность (1 балл):** Книги, которые пользователь добавил в планы, но не прочитал (`has_read=0`)
3. **Низшая ценность (0 баллов):** "Холодные" кандидаты — книги, с которыми пользователь никогда не взаимодействовал, но которые были добавлены в пул кандидатов на основе рекомендаций базовой модели

Для каждого пользователя в `candidates.csv` предоставляется смешанный список, состоящий из его реальных взаимодействий в тестовом периоде (и прочитанных, и запланированных) плюс "холодные" кандидаты. Задача модели — правильно упорядочить этот список так, чтобы прочитанные книги оказались на самых первых позициях, запланированные — ниже прочитанных, но выше "холодных" кандидатов.

Это задача **предсказания конверсии** (conversion prediction) с элементами "cold start", замаскированная под Learning-to-Rank (LTR). Модель должна научиться выделять "золото" (прочитанные), "серебро" (запланированные) и "пустую породу" ("холодные" кандидаты), проверяя навыки построения моделей, способных различать силу сигналов взаимодействия и предсказывать конверсию из интереса в фактическое потребление контента.

### 1.1. Особенности задачи

**Временное разделение:** Обучающая выборка (`train.csv`) содержит историю взаимодействий пользователей до определенного момента времени (T_global), а тестовые данные (кандидаты для ранжирования) относятся к более позднему периоду. Это обеспечивает реалистичность задачи: участники должны предсказать будущие взаимодействия на основе прошлых.

**Смешанные кандидаты:** Для каждого пользователя в `candidates.csv` предоставляется смешанный список, состоящий из:
- Всех книг, с которыми он взаимодействовал в тестовом периоде (и прочитанные, и запланированные)
- "Холодных" кандидатов — до 15 дополнительных книг, сгенерированных базовой рекомендательной моделью (ALS), с которыми пользователь никогда не взаимодействовал

Это делает задачу более сложной и реалистичной: участники должны не только отличать прочитанные книги от запланированных, но и отфильтровать "холодных" кандидатов, которые не представляют реального интереса пользователя.

**Временные метки:** В обучающей выборке (`train.csv`) присутствуют временные метки (`timestamp`), что позволяет участникам строить временные модели и анализировать паттерны взаимодействий. Однако в `candidates.csv` временные метки не предоставляются, что требует использования других признаков для ранжирования и усложняет задачу.

**Изоляция данных:** Пользователи Stage 2 полностью изолированы от пользователей Stage 1, что гарантирует независимость этапов соревнования.



---



## 2. Бейзлайн-решение



Для быстрого старта предоставлено бейзлайн-решение, которое можно и нужно использовать в качестве отправной точки для разработки собственного решения.



**Бейзлайн расположен по ссылке:** [https://github.com/Orange-Hack/nto-ai-25-26-team-baseline](https://github.com/Orange-Hack/nto-ai-25-26-team-baseline)



**Рекомендация:** Для старта работы рекомендуется сделать Fork репозитория. Это позволит бесшовно получать обновления бейзлайна через синхронизацию с оригинальным репозиторием.



Бейзлайн содержит:

- Полностью рабочий пайплайн обучения и предсказания

- Примеры feature engineering (агрегированные признаки, работа с текстом через TF-IDF и BERT)

- Структуру проекта и необходимые утилиты для валидации решения



Рекомендуется изучить бейзлайн перед началом работы над задачей.



---



## 3. Данные



Участникам предоставляется набор файлов, содержащий историю взаимодействий, пулы кандидатов для ранжирования и необходимые метаданные.

**Основные файлы:**
- `train.csv` — обучающая история взаимодействий (с временными метками)
- `targets.csv` — список пользователей для ранжирования
- `candidates.csv` — пулы кандидатов для каждого пользователя (без временных меток)
- `books.csv`, `users.csv`, `genres.csv`, `book_genres.csv`, `book_descriptions.csv` — метаданные

> **Подробное описание** состава файлов, структуры таблиц, полей и принципов формирования данных вынесено в сопроводительный документ: «Этап 2Б: Описание данных и формата решений».



---



## 4. Формат решения



Файл с решением должен быть представлен в формате CSV с разделителем запятая (`,`).

> **Подробные требования** к структуре колонок, типам данных и ограничениям описаны в сопроводительном документе: «Этап 2Б: Описание данных и формата решений».



---



## 5. Метрика оценки



Итоговый балл рассчитывается по метрике **NDCG@20 (Normalized Discounted Cumulative Gain at 20)** — стандартной метрике для задач ранжирования с многоуровневой релевантностью.

### 5.1. Почему NDCG@20?

NDCG@20 идеально подходит для нашей задачи, потому что:

1. **Поддерживает многоуровневую релевантность:** Метрика создана для оценки ранжирования, где элементы имеют разную "ценность" (в нашем случае: 2 балла за прочитанные, 1 за запланированные, 0 за "холодных" кандидатов).

2. **Наказывает за неправильный порядок:** Если вы поставите запланированную книгу (1 балл) выше прочитанной (2 балла), метрика сильно снизится. Это гарантирует, что модель правильно понимает иерархию ценности взаимодействий.

3. **Учитывает позиции:** Чем выше в списке находится релевантная книга, тем больше она вносит вклад в метрику. Это поощряет правильное ранжирование не только по уровням, но и внутри каждого уровня.

4. **Справедливость:** Метрика нормирована на идеальный результат, что позволяет сравнивать пользователей с разным количеством взаимодействий.

### 5.2. NDCG@20 (Normalized Discounted Cumulative Gain at 20)

Для каждого пользователя рассчитывается **NDCG@20** на основе трехуровневой релевантности:

**Шаг 1: Присвоение баллов релевантности**
Для каждой книги в вашем ранжированном списке присваивается балл релевантности:

- rel(r_i) = 2, если книга прочитана пользователем (присутствует в `book_id_list_read`)
- rel(r_i) = 1, если книга добавлена в планы (присутствует в `book_id_list_planned`)
- rel(r_i) = 0, если книга является "холодным" кандидатом (отсутствует в обоих списках)

**Шаг 2: Расчет DCG (Discounted Cumulative Gain)**

$$
\mathrm{DCG@20}(u) = \sum_{i=1}^{\min(|R(u)|, 20)} \frac{rel(r_i)}{\log_2(i+1)}
$$

**Шаг 3: Расчет IDCG (Ideal DCG)**
Идеальный DCG рассчитывается для идеального ранжирования, где все книги отсортированы по убыванию релевантности:

$$
\mathrm{IDCG@20}(u) = \sum_{i=1}^{\min(|R(u)|, 20)} \frac{rel_{ideal}(r_i)}{\log_2(i+1)}
$$

где rel_ideal — это список баллов релевантности, отсортированный по убыванию (сначала все двойки, потом все единицы, потом все нули).

**Шаг 4: Нормализация**

$$
\mathrm{NDCG@20}(u) = \frac{\mathrm{DCG@20}(u)}{\mathrm{IDCG@20}(u)}
$$

**Итоговая метрика — среднее значение по всем пользователям:**

$$
\overline{\mathrm{NDCG@20}} = \frac{1}{N} \sum_{j=1}^N \mathrm{NDCG@20}(u_j)
$$

**Обработка edge case:** Если все релевантности равны 0 (например, пользователь не прочитал и не запланировал ни одной книги из кандидатов), метрика равна 0.0.

**Обозначения:**
- $N$ — количество пользователей в выборке
- $u$ — конкретный пользователь
- $\mathrm{rel}(r_i)$ — балл релевантности книги на позиции $i$ (0, 1, или 2)
- $R(u)$ — ваш ранжированный список книг для пользователя $u$ (до 20 книг, или все доступные кандидаты, если их меньше 20)

### 5.3. Итоговый балл (Score)

Итоговый балл равен NDCG@20:

$$
\mathrm{Score} = \overline{\mathrm{NDCG@20}}
$$

**Чем выше Score, тем лучше результат.** Лидерборд сортируется по убыванию значения Score.

### 5.4. Пример расчета

Пусть для пользователя $u$:
- Кандидаты (10 книг): `[A, B, C, D, E, F, G, H, I, J]`
- Прочитанные книги: `{E, F}` (2 книги, релевантность = 2)
- Запланированные книги: `{A, C}` (2 книги, релевантность = 1)
- "Холодные" кандидаты: `{B, D, G, H, I, J}` (6 книг, релевантность = 0)

**Вариант 1: Правильный порядок**
Ваш submission: `[E, F, A, C, B, D, G, H, I, J]`

**Relevance scores:** `[2, 2, 1, 1, 0, 0, 0, 0, 0, 0]`

**DCG@20:**
- Позиция 1 (E): 2 / log_2(2) = 2.0
- Позиция 2 (F): 2 / log_2(3) = 1.261
- Позиция 3 (A): 1 / log_2(4) = 0.5
- Позиция 4 (C): 1 / log_2(5) = 0.431
- Остальные: 0

**DCG = 2.0 + 1.261 + 0.5 + 0.431 = 4.192**

**IDCG@20:** Для идеального ранжирования (сначала все двойки, потом единицы, потом нули) — такой же результат: **4.192**

**NDCG@20 = 4.192 / 4.192 = 1.0** ✓

**Вариант 2: Неправильный порядок**
Ваш submission: `[A, B, C, D, E, F, G, H, I, J]` (запланированные выше прочитанных!)

**Relevance scores:** `[1, 0, 1, 0, 2, 2, 0, 0, 0, 0]`

**DCG@20:**
- Позиция 1 (A): 1 / log_2(2) = 1.0
- Позиция 2 (B): 0 / log_2(3) = 0
- Позиция 3 (C): 1 / log_2(4) = 0.5
- Позиция 4 (D): 0 / log_2(5) = 0
- Позиция 5 (E): 2 / log_2(6) = 0.774
- Позиция 6 (F): 2 / log_2(7) = 0.712
- Остальные: 0

**DCG = 1.0 + 0 + 0.5 + 0 + 0.774 + 0.712 = 2.986**

**IDCG@20:** Все еще **4.192** (идеальное ранжирование)

**NDCG@20 = 2.986 / 4.192 = 0.712** ✗

Как видите, неправильный порядок (запланированные выше прочитанных) **сильно снижает** метрику, даже если все книги найдены.



---



## 6. Условия соревнования



### 6.1. Проверка и лидерборд

- **Публичный лидерборд (Public):** Рассчитывается на видимой части тестовых данных. Результат обновляется после каждой успешной отправки решения.
- **Приватный лидерборд (Private):** Рассчитывается на скрытой части тестовых данных. Финальные результаты соревнования определяются исключительно по этому лидерборду.
- **Лимиты:** Устанавливается ограничение на количество отправок в сутки и на весь этап. Точные значения будут указаны на странице соревнования.

### 6.2. Ограничения

- Запрещено использовать любые внешние данные и предварительно обученные модели, за исключением общедоступных (например, для обработки текста).
- Решение должно быть полностью автономным и не требовать доступа к сети Интернет во время работы.

Подробнее см. Правила участия
